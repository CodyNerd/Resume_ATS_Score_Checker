"""
LLM Client for Resume ATS Analysis using NVIDIA Nemotron
"""

import json
import re
import os
from openai import OpenAI
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Get configuration from environment variables
NVIDIA_API_KEY = os.getenv("NVIDIA_API_KEY")
NVIDIA_BASE_URL = os.getenv("NVIDIA_BASE_URL", "https://integrate.api.nvidia.com/v1")
NVIDIA_MODEL = os.getenv("NVIDIA_MODEL", "nvidia/llama-3.3-nemotron-super-49b-v1.5")

# Validate API key
if not NVIDIA_API_KEY:
    raise ValueError("NVIDIA_API_KEY environment variable is required. Please set it in your .env file or environment.")

# Initialize NVIDIA API client
client = OpenAI(
    base_url=NVIDIA_BASE_URL,
    api_key=NVIDIA_API_KEY
)

def analyze_resume(resume_text: str, job_description: str) -> dict:
    """
    Analyze resume against job description using NVIDIA Nemotron LLM
    
    Args:
        resume_text (str): Extracted text from resume
        job_description (str): Job description text
    
    Returns:
        dict: Analysis results containing ATS score, keywords, and suggestions
    """
    
    # Simplified prompt that forces JSON output without thinking
    prompt = f"""Analyze this resume against the job description and return ONLY a JSON object with ATS analysis.

RESUME: {resume_text[:2000]}

JOB DESCRIPTION: {job_description[:1000]}

Return ONLY this JSON structure (no other text):
{{
    "ats_score": 75,
    "score_summary": "Brief assessment of competitiveness",
    "matched_keywords": ["keyword1", "keyword2", "keyword3"],
    "missing_keywords": ["missing1", "missing2", "missing3"],
    "text_replacements": [
        {{
            "section": "Experience",
            "original_text": "brief original text",
            "improved_text": "improved version with metrics",
            "reason": "why this helps"
        }}
    ],
    "detailed_suggestions": [
        {{
            "priority": "High",
            "category": "Keywords",
            "issue": "specific issue",
            "solution": "specific solution",
            "expected_impact": "expected result"
        }}
    ],
    "score_breakdown": {{"keywords": 18, "experience": 20, "skills": 16, "education": 12, "formatting": 14}},
    "score_explanation": "Brief explanation of scoring",
    "next_steps": "1. First step. 2. Second step. 3. Third step."
}}"""

    try:
        # Make API call to NVIDIA Nemotron
        completion = client.chat.completions.create(
            model=NVIDIA_MODEL,
            messages=[
                {"role": "system", "content": "You are an expert ATS resume evaluator. You MUST respond with ONLY valid JSON. Do not include any thinking, explanations, or other text. Start your response with { and end with }."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,  # Very low temperature for consistent JSON
            top_p=0.8,
            max_tokens=4096,
            frequency_penalty=0,
            presence_penalty=0,
            stream=False
        )
        
        # Extract response content
        response_content = completion.choices[0].message.content
        # Clean response content - remove thinking tags and markdown formatting
        response_content = response_content.strip()
        
        # Remove thinking tags if present
        if '<think>' in response_content:
            # Extract content after </think> tag
            think_end = response_content.find('</think>')
            if think_end != -1:
                response_content = response_content[think_end + 8:].strip()
        
        # Remove markdown formatting
        if response_content.startswith('```json'):
            response_content = response_content[7:]
        if response_content.startswith('```'):
            response_content = response_content[3:]
        if response_content.endswith('```'):
            response_content = response_content[:-3]
        response_content = response_content.strip()
        
        # Try to find JSON object if there's extra text
        json_start = response_content.find('{')
        json_end = response_content.rfind('}')
        if json_start != -1 and json_end != -1 and json_end > json_start:
            response_content = response_content[json_start:json_end + 1]
        
        # Parse JSON response
        try:
            result = json.loads(response_content)
            
            # Validate and structure the result
            validated_result = {
                'ats_score': min(100, max(0, int(result.get('ats_score', 0)))),
                'score_summary': result.get('score_summary', 'Analysis completed'),
                'matched_keywords': result.get('matched_keywords', [])[:15],
                'missing_keywords': result.get('missing_keywords', [])[:15],
                'text_replacements': result.get('text_replacements', [])[:10],
                'detailed_suggestions': result.get('detailed_suggestions', [])[:10],
                'score_breakdown': result.get('score_breakdown', {}),
                'score_explanation': result.get('score_explanation', 'Score analysis not available.'),
                'next_steps': result.get('next_steps', 'Next steps not available.'),
                # Legacy compatibility
                'suggestions': [f"{item.get('category', 'General')}: {item.get('solution', item.get('suggestion', str(item)))}" 
                              for item in result.get('detailed_suggestions', [])],
                'feedback': result.get('score_explanation', 'Analysis completed successfully.')
            }
            
            return validated_result
            
        except json.JSONDecodeError as e:
            # If JSON parsing fails, try to extract information using regex
            return parse_fallback_response(response_content)
    
    except Exception as e:
        # Return error result with some sample data for testing
        return {
            'ats_score': 65,
            'score_summary': 'Analysis completed with fallback data due to API issues',
            'matched_keywords': ['Python', 'Machine Learning', 'Data Analysis'],
            'missing_keywords': ['AWS', 'Docker', 'Kubernetes'],
            'text_replacements': [
                {
                    'section': 'Experience',
                    'original_text': 'Worked on projects',
                    'improved_text': 'Developed and deployed 3+ projects using Python and machine learning frameworks',
                    'reason': 'Added specific technologies and quantified achievements'
                }
            ],
            'detailed_suggestions': [
                {
                    'priority': 'High',
                    'category': 'Keywords',
                    'issue': 'Missing key technologies from job description',
                    'solution': 'Add cloud technologies and DevOps tools to skills section',
                    'expected_impact': 'Improve ATS matching by 15-20 points'
                }
            ],
            'score_breakdown': {
                'keywords': 15,
                'experience': 18,
                'skills': 14,
                'education': 10,
                'formatting': 8
            },
            'score_explanation': 'Fallback analysis due to API issues. Keywords (15/25): Basic coverage. Experience (18/25): Relevant but needs metrics. Skills (14/20): Good foundation. Education (10/15): Adequate. Formatting (8/15): Could be improved.',
            'next_steps': '1. Add missing keywords from job description. 2. Quantify achievements with specific numbers. 3. Improve resume formatting and structure.',
            'suggestions': ['Add more relevant keywords', 'Quantify your achievements', 'Improve formatting'],
            'feedback': "Analysis completed with fallback data due to technical issues."
        }

def parse_fallback_response(response_text: str) -> dict:
    """
    Fallback parser for non-JSON responses
    
    Args:
        response_text (str): Raw response text from LLM
    
    Returns:
        dict: Parsed analysis results
    """
    
    # Try to extract ATS score
    score_match = re.search(r'(?:ats_score|score).*?(\d+)', response_text, re.IGNORECASE)
    ats_score = int(score_match.group(1)) if score_match else 50
    
    # Extract keywords (simple approach)
    matched_keywords = []
    missing_keywords = []
    suggestions = []
    
    # Look for common patterns
    lines = response_text.split('\n')
    current_section = None
    
    for line in lines:
        line = line.strip()
        if 'matched' in line.lower() and 'keyword' in line.lower():
            current_section = 'matched'
        elif 'missing' in line.lower() and 'keyword' in line.lower():
            current_section = 'missing'
        elif 'suggestion' in line.lower() or 'recommend' in line.lower():
            current_section = 'suggestions'
        elif line.startswith('â€¢') or line.startswith('-') or line.startswith('*'):
            item = line[1:].strip()
            if current_section == 'matched' and len(matched_keywords) < 10:
                matched_keywords.append(item)
            elif current_section == 'missing' and len(missing_keywords) < 10:
                missing_keywords.append(item)
            elif current_section == 'suggestions' and len(suggestions) < 8:
                suggestions.append(item)
    
    return {
        'ats_score': min(100, max(0, ats_score)),
        'matched_keywords': matched_keywords,
        'missing_keywords': missing_keywords,
        'suggestions': suggestions if suggestions else ["Consider adding more relevant keywords from the job description"],
        'feedback': "Analysis completed with fallback parsing. Results may be limited."
    }